import json
import logging
import os
import time
import re
from flask import Flask, request, jsonify
from google.cloud import firestore
from google.cloud import storage
from openai import OpenAI

app = Flask(__name__)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("app.log", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    db = firestore.Client()
    logger.info("Firestore í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"Firestore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    db = None

# GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    gcs_client = storage.Client()
    bucket_name = os.getenv("GCS_BUCKET_NAME", "rjcode")
    bucket = gcs_client.bucket(bucket_name)
    logger.info(f"GCS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ, ë²„í‚·: {bucket_name}")
except Exception as e:
    logger.error(f"GCS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    gcs_client = None
    bucket = None

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
try:
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    logger.error(f"OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    openai_client = None

# ì¼ë³¸ì–´ ê°ì§€ í•¨ìˆ˜
def needs_translation(title: str) -> bool:
    if not title or not isinstance(title, str):
        logger.debug(f"ë²ˆì—­ ë¶ˆí•„ìš”: ì œëª©ì´ ë¹„ì–´ ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {title}")
        return False
    # íˆë¼ê°€ë‚˜(\u3040-\u309F), ê°€íƒ€ì¹´ë‚˜(\u30A0-\u30FF), í•œì(\u4E00-\u9FFF) í¬í•¨ ì—¬ë¶€ í™•ì¸
    has_japanese = bool(re.search(r'[\u3040-\u30FF\u4E00-\u9FFF]', title))
    logger.debug(f"ì¼ë³¸ì–´ ê°ì§€ ê²°ê³¼ '{title}': {'ê°ì§€ë¨' if has_japanese else 'ê°ì§€ë˜ì§€ ì•ŠìŒ'}")
    return has_japanese

# GCS ê²½ë¡œ ìƒì„± í•¨ìˆ˜
def get_gcs_path(platform, rj_code):
    # RJ ì½”ë“œì—ì„œ ìˆ«ì ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: RJ123456 -> 123456)
    number_part = rj_code[2:] if rj_code.startswith('RJ') else rj_code
    # ìˆ«ì ë¶€ë¶„ì˜ ì• ë‘ ê¸€ì ì¶”ì¶œ
    prefix = number_part[:2] if len(number_part) >= 2 else number_part.zfill(2)
    return f"{platform}/{prefix}/{rj_code}.json"

# GCSì—ì„œ ìºì‹œ ë¶ˆëŸ¬ì˜¤ê¸°
def get_cached_data(platform, identifier):
    if not bucket:
        logger.warning("GCS ë²„í‚·ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return None
    rj_code = identifier.upper().replace('-', '').replace('_', '').strip()
    blob_path = get_gcs_path(platform, rj_code)
    blob = bucket.blob(blob_path)

    if blob.exists():
        content = blob.download_as_text()
        data = json.loads(content)

        # âœ… 404 í˜¹ì€ ì˜¤ë¥˜ ìƒíƒœë©´ ë°”ë¡œ ë¦¬í„´
        if data.get("status") == "404" or data.get("permanent_error"):
            logger.info(f"[GCS ìºì‹œ] 404 í™•ì¸: {platform}:{rj_code}")
            return data

        # âœ… íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ëŠ” ê²½ìš° ë¬´íš¨
        if not data.get("timestamp"):
            logger.warning(f"[GCS ìºì‹œ] íƒ€ì„ìŠ¤íƒ¬í”„ ì—†ìŒ: {platform}:{rj_code}")
            return None

        logger.info(f"[GCS ìºì‹œ] ì¡°íšŒ ì„±ê³µ: {platform}:{rj_code}")
        return data
    return None

# GCSì— ìºì‹œ ì €ì¥
def cache_data(platform, rj_code, data):
    if not bucket:
        logger.warning("GCS ë²„í‚·ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return
    try:
        blob_path = get_gcs_path(platform, rj_code)
        blob = bucket.blob(blob_path)
        blob.upload_from_string(json.dumps(data, ensure_ascii=False), content_type='application/json')
        logger.info(f"[GCS ìºì‹œ] ì €ì¥ ì™„ë£Œ: {blob_path}")
    except Exception as e:
        logger.error(f"[GCS ìºì‹œ ì˜¤ë¥˜] ì €ì¥ ì‹¤íŒ¨: {platform}/{rj_code}, ì˜¤ë¥˜: {e}", exc_info=True)

# íƒœê·¸ ìºì‹œ
def get_cached_tag(tag_jp):
    if not db:
        return None
    try:
        safe_tag_id = normalize_tag_id(tag_jp)
        doc_ref = db.collection('tags').document('jp_to_kr').collection('mappings').document(safe_tag_id)
        doc = doc_ref.get()
        if doc.exists:
            return doc.to_dict()
        return None
    except Exception as e:
        logger.error(f"íƒœê·¸ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {tag_jp}: {e}")
        return None

def normalize_tag_id(tag_jp):
    # Firestore ë¬¸ì„œ IDë¡œ ì“¸ ìˆ˜ ìˆë„ë¡ ìŠ¬ë˜ì‹œ ì œê±° ë˜ëŠ” ëŒ€ì²´
    return tag_jp.replace("/", "-")

def cache_tag(tag_jp, tag_kr, priority):
    if not db:
        return
    try:
        safe_tag_id = normalize_tag_id(tag_jp)
        normalized_tag_kr = normalize_tag_id(tag_kr)  # ğŸ”¥ í•˜ì´í”ˆ ë“±ìœ¼ë¡œ ì •ì œ
        doc_ref = db.collection('tags').document('jp_to_kr').collection('mappings').document(safe_tag_id)
        doc_ref.set({
            'tag_jp': tag_jp,        # ì›ë³¸ ê·¸ëŒ€ë¡œ ì €ì¥
            'tag_kr': normalized_tag_kr,
            'priority': priority
        })
        logger.info(f"íƒœê·¸ ìºì‹œ ì €ì¥: {tag_jp} â†’ {normalized_tag_kr} (ID: {safe_tag_id})")
    except Exception as e:
        logger.error(f"íƒœê·¸ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {tag_jp}: {e}")

# GPT ë²ˆì—­
def translate_with_gpt_batch(tags, title_jp=None, batch_idx=""):
    if not openai_client:
        logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return tags, title_jp
    try:
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
        prompt = (
            "ë‹¹ì‹ ì€ ì¼ë³¸ì–´ì—ì„œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.\n"
            "ì•„ë˜ì˜ íƒœê·¸ë“¤ê³¼ ì œëª©ì„ ë¬¸ë§¥ì— ë§ê²Œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\n"
            "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ë©°, ì˜ˆì‹œì™€ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.\n"
            "ì œëª©(title)ë²ˆì—­ì€ í•œêµ­ì–´ë‚˜ ì˜ì–´ì¸ ê²½ìš°ë§Œ ìƒëµí•´ë„ ë©ë‹ˆë‹¤.\n\n"
            "ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:\n"
            "{\n"
            "  \"tags\": [\"ë²ˆì—­ëœíƒœê·¸1\", \"ë²ˆì—­ëœíƒœê·¸2\", ...],\n"
            "  \"title\": \"ë²ˆì—­ëœì œëª©\"\n"
            "}\n\n"
            "ì˜ˆì‹œ ì…ë ¥/ì¶œë ¥:\n"
            "Input:\n"
            "Tags: RPG, ã‚¢ã‚¯ã‚·ãƒ§ãƒ³\n"
            "Title: å°‘å¥³ã®å†’é™º\n"
            "Output:\n"
            "{\n"
            "  \"tags\": [\"RPG\", \"ì•¡ì…˜\"],\n"
            "  \"title\": \"ì†Œë…€ì˜ ëª¨í—˜\"\n"
            "}\n\n"
            f"Input:\n"
            f"Tags: {', '.join(tags) if tags else 'ì—†ìŒ'}\n"
            f"Title: {title_jp if title_jp else 'ì—†ìŒ'}\n"
            "Output:"
        )

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a translator specializing in Japanese to Korean."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=200
        )
        response_text = response.choices[0].message.content.strip()
        logger.debug(f"GPT ì‘ë‹µ: {batch_idx}: {response_text}")

        # JSON íŒŒì‹±
        try:
            response_json = json.loads(response_text)
            translated_tags = response_json.get('tags', tags)
            translated_title = response_json.get('title', title_jp) if title_jp else title_jp
        except json.JSONDecodeError:
            logger.warning(f"ì˜ëª»ëœ JSON ì‘ë‹µ: {batch_idx}: {response_text}")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ íŒŒì‹±
            parts = response_text.split(';')
            translated_tags = [t.strip() for t in parts[0].split(',')][:len(tags)]
            translated_title = parts[1].strip() if len(parts) > 1 and title_jp else title_jp

        # ë²ˆì—­ ì‹¤íŒ¨ ê°ì§€
        if title_jp and translated_title and needs_translation(translated_title):
            logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨: {batch_idx}: translated_title={translated_title}ì€ ì—¬ì „íˆ ì¼ë³¸ì–´")
            translated_title = title_jp  # ì¼ë³¸ì–´ë¡œ ë°˜í™˜ëœ ê²½ìš° ì›ë³¸ ìœ ì§€

        logger.info(f"ë²ˆì—­ ì™„ë£Œ: {batch_idx}: tags={translated_tags}, title={translated_title}")
        return translated_tags, translated_title
    except Exception as e:
        logger.error(f"GPT ë²ˆì—­ ì˜¤ë¥˜: ë°°ì¹˜ {batch_idx}: {e}")
        return tags, title_jp  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë˜ ì œëª© ìœ ì§€

# RJ ë°ì´í„° ì²˜ë¦¬
def process_rj_item(item):
    if 'error' in item:
        rj_code = item.get('rj_code') or item.get('title') or item.get('original') or 'unknown'
        if not re.match(r'^RJ\d{6,8}$', rj_code, re.IGNORECASE):
            logger.warning(f"[ì˜¤ë¥˜ í•­ëª©] ìœ íš¨í•˜ì§€ ì•Šì€ RJ ì½”ë“œ, ì €ì¥ ìƒëµ: {rj_code}")
            return {
                'rj_code': rj_code,
                'error': item.get('error'),
                'platform': 'rj',
                'timestamp': time.time()
            }
        error_data = {
            'rj_code': rj_code,
            'platform': 'rj',
            'title': "ì•Œ ìˆ˜ ì—†ìŒ",
            'title_kr': "ì•Œ ìˆ˜ ì—†ìŒ",
            'title_jp': "ä¸æ˜",
            'tags': ["ê¸°íƒ€"],
            'tags_jp': ["ãã®ä»–"],
            'primary_tag': "ê¸°íƒ€",
            'error': item.get('error'),
            'timestamp': time.time()
        }
        logger.warning(f"[ì˜¤ë¥˜ í•­ëª©] ìºì‹œì— ì €ì¥: {rj_code}")
        cache_data('rj', rj_code, error_data)
        return error_data

    rj_code = item.get('rj_code')
    cached = get_cached_data('rj', rj_code)
    if cached and cached.get('title_kr') and not needs_translation(cached.get('title_kr')):
        logger.debug(f"ìºì‹œ ë°ì´í„° ì‚¬ìš©: {rj_code}: title_kr={cached.get('title_kr')}")
        return cached

    tags_jp = item.get('tags_jp', [])
    tags_jp = [tag.strip() for tag in tags_jp]  # ê³µë°± ì œê±°
    tags_jp = [normalize_tag_id(tag) for tag in tags_jp]
    title_jp = item.get('title_jp', '')
    tags_kr = []
    tags_to_translate = []
    tag_priorities = []

    # RJ ì½”ë“œ ì œê±° í•¨ìˆ˜
    def clean_title(title, rj_code):
        if not title or not rj_code:
            return title
        patterns = [
            rf"[\[\(]?\b{rj_code}\b[\]\)]?[)\s,;ï¼š]*",
            rf"[ _\-]?\bRJ\s*{rj_code[2:]}\b",
            rf"\b{rj_code}\b"
        ]
        cleaned = title
        for pattern in patterns:
            cleaned = re.sub(pattern, "", cleaned, flags=re.IGNORECASE).strip()
        return cleaned

    # title_jp ì •ì œ
    cleaned_title_jp = clean_title(title_jp, rj_code)

    for tag in tags_jp:
        cached_tag = get_cached_tag(tag)
        if cached_tag:
            kr = cached_tag['tag_kr']
            priority = cached_tag.get('priority', 10)
            tags_kr.append(kr)
            tag_priorities.append(priority)
        else:
            tags_to_translate.append(tag)
            tag_priorities.append(10)

    translated_tags = tags_jp
    translated_title = cleaned_title_jp

    if needs_translation(cleaned_title_jp) or tags_to_translate:
        logger.debug(f"ë²ˆì—­ ìš”ì²­: {rj_code}: title_jp={cleaned_title_jp}, tags={tags_to_translate}")
        translated_tags, translated_title = translate_with_gpt_batch(
            tags_to_translate,
            cleaned_title_jp if needs_translation(cleaned_title_jp) else None,
            batch_idx=rj_code
        )
        # ë²ˆì—­ëœ ì œëª©ë„ RJ ì½”ë“œ ì œê±°
        translated_title = clean_title(translated_title or cleaned_title_jp, rj_code)
        for i, (jp, kr) in enumerate(zip(tags_to_translate, translated_tags)):
            existing = get_cached_tag(jp)
            priority = existing.get("priority", 10) if existing else 10
            tags_kr.append(kr)
            tag_priorities.append(priority)
            cache_tag(jp, kr, priority)
    else:
        logger.debug(f"ë²ˆì—­ ë¶ˆí•„ìš”: {rj_code}: title_jp={cleaned_title_jp}")

    tag_with_priority = list(zip(tags_kr, tag_priorities))
    tag_with_priority.sort(key=lambda x: x[1], reverse=True)
    tags_kr_sorted = [tag for tag, _ in tag_with_priority]
    primary_tag = tags_kr_sorted[0] if tags_kr_sorted else "ê¸°íƒ€"

    processed_data = {
        'rj_code': rj_code,
        'title_jp': cleaned_title_jp,
        'title_kr': translated_title or cleaned_title_jp or rj_code,
        'primary_tag': primary_tag,
        'tags_jp': tags_jp,
        'tags': tags_kr_sorted,
        'release_date': item.get('release_date', 'N/A'),
        'thumbnail_url': item.get('thumbnail_url', ''),
        'rating': item.get('rating', 0.0),
        'link': item.get('link', ''),
        'platform': 'rj',
        'maker': item.get('maker', ''),
        'timestamp': time.time()
    }

    cache_data('rj', rj_code, processed_data)
    logger.info(f"RJ í•­ëª© ì²˜ë¦¬ ì™„ë£Œ: {rj_code}, title_kr={processed_data['title_kr']}")
    return processed_data

# Steam ë°ì´í„° ì²˜ë¦¬
def process_steam_item(identifier):
    return {
        'title': identifier,
        'title_kr': identifier,
        'primary_tag': "ê¸°íƒ€",
        'tags': ["ê¸°íƒ€"],
        'thumbnail_url': '',
        'platform': 'ê¸°íƒ€'  # ğŸ”¥ platformì„ "steam" â†’ "ê¸°íƒ€"ë¡œ ë³€ê²½
        # 'timestamp': time.time()
    }

# ì•„ì´í…œ ì•ˆì „ ì²˜ë¦¬ í•¨ìˆ˜
def process_item_with_safety(item):
    """ì•ˆì „í•˜ê²Œ ì•„ì´í…œì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    platform = item.get("platform", "rj")
    rj_code = item.get("rj_code")
    
    # ìºì‹œ ì €ì¥ ìš”ì²­ì¼ ê²½ìš° (í¬ë¡¤ë§ ì„±ê³µ or ì‹¤íŒ¨ í›„)
    if isinstance(item, dict) and item.get("timestamp"):
        title = item.get("title_kr") or item.get("title") or rj_code
        
        # ìˆ˜ì •: ì €ì¥ ì „ title_kr ê²€ì¦
        if item.get("title_kr") and not item.get("title_jp") and not item.get("skip_translation"):
            # title_krë§Œ ìˆê³  title_jpê°€ ì—†ëŠ” ê²½ìš°, íŒŒì¼ëª…ì´ ì˜ëª» ì €ì¥ëœ ê²ƒìœ¼ë¡œ ì˜ì‹¬
            original_name = item.get("original") or item.get("title") or ""
            if original_name and item.get("title_kr") == clean_rj_code(original_name, rj_code):
                logger.warning(f"[ì˜ì‹¬ í•­ëª©] {platform}:{rj_code}: title_krì´ íŒŒì¼ëª…ê³¼ ë™ì¼")
                # title_krì„ ë¹„ìš°ê³  original_filename í•„ë“œì— ì €ì¥
                item["original_filename"] = original_name
                item["title_kr"] = "âš ï¸ " + item["title_kr"]  # ê²½ê³  í‘œì‹œ ì¶”ê°€
                
        # skip_translation í”Œë˜ê·¸ ë˜ëŠ” 404 ìƒíƒœì´ë©´ ë²ˆì—­ ì—†ì´ ë°”ë¡œ ì²˜ë¦¬
        if item.get("skip_translation") or item.get("status") == "404" or item.get("permanent_error"):
            logger.info(f"[ì§ì ‘ ì €ì¥] {platform}:{rj_code}")
            processed = process_and_save_rj_item(item)  # ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©
            return processed
        # ê¸°ì¡´ ë²ˆì—­/ì €ì¥ ì¡°ê±´
        elif platform == "rj" and (not item.get("title_kr") or not item.get("tags")):
            logger.info(f"[ë²ˆì—­ ë° ì €ì¥] {platform}:{rj_code}")
            processed = process_and_save_rj_item(item)  # ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©
            return processed
        else:
            # ìˆ˜ì •: original_filename í•„ë“œ ì¶”ê°€
            original_name = item.get("original") or item.get("title") or ""
            if original_name:
                item["original_filename"] = original_name
                
            cache_data(platform, rj_code, item)
            logger.info(f"[ì €ì¥ ì™„ë£Œ] {platform}/items/{rj_code}, title_kr={title}")
            return item
    
    # ìºì‹œ í™•ì¸ ìš”ì²­ì¼ ê²½ìš° ê¸°ì¡´ ë¡œì§ ìœ ì§€
    return None

# ê²Œì„ ë°ì´í„° ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸
@app.route('/games', methods=['POST'])
def process_games():
    try:
        data = request.get_json()
        logger.info(f"ìš”ì²­ ë°ì´í„° ìˆ˜ì‹ : {json.dumps(data, ensure_ascii=False)[:1000]}")
        items = data.get('items', [])
        logger.info(f"{len(items)}ê°œ í•­ëª© ì²˜ë¦¬ ì‹œì‘")

        results = []
        missing = []

        if not items:
            return jsonify({'results': [], 'missing': [], 'task_id': 'none'})

        for item in items:
            # ë¬¸ìì—´(RJ ì½”ë“œ)ë§Œ ë°›ì€ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            if isinstance(item, str):
                # RJ ì½”ë“œ íŒ¨í„´ í™•ì¸
                if re.match(r'^RJ\d{6,8}$', item, re.IGNORECASE):
                    item = {
                        "rj_code": item.upper(),
                        "platform": "rj"
                    }
                    logger.info(f"[ë¬¸ìì—´ ë³€í™˜] {item['rj_code']}")
                else:
                    item = {
                        "title": item,
                        "platform": "steam"
                    }
                    logger.info(f"[ë¬¸ìì—´ ë³€í™˜] Steam ì œëª©: {item['title']}")

            # ì´ì œ itemì€ í™•ì‹¤íˆ ë”•ì…”ë„ˆë¦¬ íƒ€ì…
            logger.info(f"[í•­ëª© ì²˜ë¦¬] {json.dumps(item, ensure_ascii=False)}")

            # ìˆ˜ì •: process_item_with_safety í•¨ìˆ˜ë¡œ ì²˜ë¦¬
            processed = process_item_with_safety(item)
            if processed:
                results.append(processed)
                continue

            # ìºì‹œ í™•ì¸ ìš”ì²­ì¼ ê²½ìš°
            rj_code = item.get("rj_code") if isinstance(item, dict) else None
            platform = item.get("platform", "rj") if isinstance(item, dict) else "rj"

            # RJ ì—†ëŠ” ê²½ìš° steam ì²˜ë¦¬
            if not rj_code:
                title = item.get("title", "untitled") if isinstance(item, dict) else str(item)
                steam_fallback = process_steam_item(title)
                logger.info(f"[Steam ëª¨ë“œ] ì œëª©={steam_fallback.get('title')}")
                results.append(steam_fallback)
                continue

            # ìºì‹œ í™•ì¸
            cached = get_cached_data(platform, rj_code)
            if cached and cached.get("timestamp"):
                logger.info(f"[ìºì‹œ ì¡°íšŒ ì„±ê³µ] {platform}:{rj_code}")
                results.append(cached)
            else:
                logger.info(f"[ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨] {platform}:{rj_code}")
                missing.append(rj_code)

        task_id = request.headers.get('X-Cloud-Trace-Context', 'manual_task')[:36]
        logger.info(f"ì‘ë‹µ ë°˜í™˜: task_id={task_id}, ê²°ê³¼={len(results)}, ëˆ„ë½={len(missing)}")
        return jsonify({'results': results, 'missing': missing, 'task_id': task_id})

    except Exception as e:
        logger.error(f"ê²Œì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'error': str(e)}), 500

# ì§„í–‰ ìƒí™© ì—”ë“œí¬ì¸íŠ¸
@app.route('/progress/<task_id>', methods=['GET'])
def get_progress(task_id):
    try:
        logger.info(f"ì§„í–‰ ìƒí™© ìš”ì²­: task_id={task_id}")
        return jsonify({'completed': 0, 'total': 1, 'status': 'completed'})
    except Exception as e:
        logger.error(f"ì§„í–‰ ìƒí™© ì¡°íšŒ ì˜¤ë¥˜: task_id={task_id}: {e}")
        return jsonify({'error': str(e)}), 500

@app.route("/sync-tags", methods=["POST"])
def sync_tags_to_games():
    try:
        logger.info("ëª¨ë“  ê²Œì„ì˜ íƒœê·¸ ë™ê¸°í™” ì‹œì‘")

        # 1. íƒœê·¸ ë³€í™˜ í…Œì´ë¸” ìƒì„±
        tag_map = {
            doc.id: doc.to_dict().get("tag_kr", doc.id)
            for doc in db.collection("tags").document("jp_to_kr").collection("mappings").stream()
        }
        tag_priority = {
            doc.id: doc.to_dict().get("priority", 10)
            for doc in db.collection("tags").document("jp_to_kr").collection("mappings").stream()
        }

        # 2. RJ ê²Œì„ ë¬¸ì„œë“¤ ì—…ë°ì´íŠ¸
        games_ref = db.collection("games").document("rj").collection("items")
        updated_count = 0

        for doc in games_ref.stream():
            game = doc.to_dict()
            tags_jp = game.get("tags_jp", [])
            if not tags_jp:
                continue

            tags_kr = [tag_map.get(jp, "ê¸°íƒ€") for jp in tags_jp]
            primary_tag = max(tags_kr, key=lambda t: tag_priority.get(t, 0), default="ê¸°íƒ€")

            games_ref.document(doc.id).update({
                "tags": tags_kr,
                "primary_tag": primary_tag
            })
            updated_count += 1

        logger.info(f"íƒœê·¸ ë™ê¸°í™” ì™„ë£Œ: {updated_count}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸")
        return jsonify({"updated": updated_count})

    except Exception as e:
        logger.error(f"íƒœê·¸ ë™ê¸°í™” ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

@app.route('/reorder-tags', methods=['POST'])
def reorder_tags():
    try:
        logger.info("íƒœê·¸ ì¬ì •ë ¬ ì‘ì—… ì‹œì‘")

        # âœ… íƒœê·¸ ìš°ì„ ìˆœìœ„ ë¡œë“œ
        tag_priority = {
            doc.id: doc.to_dict().get("priority", 10)
            for doc in db.collection("tags").document("jp_to_kr").collection("mappings").stream()
        }

        logger.info(f"{len(tag_priority)}ê°œì˜ íƒœê·¸ ìš°ì„ ìˆœìœ„ ë¡œë”© ì™„ë£Œ")

        # ğŸ”„ ì „ì²´ ê²Œì„ ìˆœíšŒ
        games_ref = db.collection("games").document("rj").collection("items")
        updated = 0
        for doc in games_ref.stream():
            data = doc.to_dict()
            tags = data.get("tags", [])
            if not tags:
                continue

            original_tags = tags[:]
            # ğŸ”½ ìš°ì„ ìˆœìœ„ ì •ë ¬
            sorted_tags = sorted(tags, key=lambda t: -tag_priority.get(t, 10))  # âœ… ë†’ì€ ì ìˆ˜ ìš°ì„ 
            primary_tag = sorted_tags[0] if sorted_tags else "ê¸°íƒ€"

            # âœ… ë³€ê²½ì‚¬í•­ ìˆì„ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
            if sorted_tags != tags or primary_tag != data.get("primary_tag"):
                doc.reference.update({
                    "tags": sorted_tags,
                    "primary_tag": primary_tag
                })
                logger.info(f"[ì—…ë°ì´íŠ¸] {doc.id}: {original_tags} â†’ {sorted_tags}")
                updated += 1

        logger.info(f"íƒœê·¸ ì¬ì •ë ¬ ì™„ë£Œ: {updated}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸")
        return jsonify({"status": "ok", "updated_documents": updated})
    except Exception as e:
        logger.error(f"íƒœê·¸ ì¬ì •ë ¬ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500

def process_and_save_rj_item(item):
    """ë²ˆì—­ë˜ì§€ ì•Šì€ RJ í•­ëª©ì„ ì²˜ë¦¬í•˜ê³  ì €ì¥"""
    rj_code = item.get("rj_code", "unknown")
    
    # ë²ˆì—­ ìŠ¤í‚µ í”Œë˜ê·¸ í™•ì¸
    if item.get("skip_translation") or item.get("status") == "404" or item.get("permanent_error"):
        logger.info(f"[ë²ˆì—­ ìŠ¤í‚µ] {rj_code}: ë²ˆì—­ ì—†ì´ ë°”ë¡œ ì €ì¥")
        
        # ìˆ˜ì •: title_krì´ ì—†ê³  ì¼ë³¸ì–´ë„ ì—†ëŠ” ê²½ìš°ì—ë§Œ íŒŒì¼ëª… ì‚¬ìš©í•˜ë©°,
        # ì´ ê²½ìš°ì—ë„ original_filename í•„ë“œì— ë”°ë¡œ ì €ì¥
        if not item.get("title_kr"):
            # title_jpê°€ ìˆëŠ” ê²½ìš° title_krì€ ë¹ˆ ìƒíƒœë¡œ ë‘ì–´ ë²ˆì—­ ê°€ëŠ¥ì„± ì—´ì–´ë‘ 
            if item.get("title_jp"):
                logger.info(f"[ë²ˆì—­ ìŠ¤í‚µ] {rj_code}: title_jp ìˆìŒ, title_krì€ ë¹„ì›Œë‘ ")
                item["original_filename"] = item.get("original") or item.get("title") or ""
            else:
                # title_jpë„ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì œí•œì ìœ¼ë¡œ originalì„ title_krë¡œ ì‚¬ìš©
                original_name = item.get("original") or item.get("title") or ""
                if original_name:
                    logger.info(f"[ë²ˆì—­ ìŠ¤í‚µ] {rj_code}: title_jp ì—†ìŒ, original ì‚¬ìš©")
                    # ëŒ€ì‹  original_filename í•„ë“œì—ë„ ì›ë³¸ì„ ì €ì¥
                    item["original_filename"] = original_name
                    item["title_kr"] = "âš ï¸ " + clean_rj_code(original_name, rj_code)
                else:
                    item["title_kr"] = ""
        
        # íƒœê·¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì •
        if not item.get("tags"):
            item["tags"] = ["ê¸°íƒ€"]
            item["primary_tag"] = "ê¸°íƒ€"
            
        cache_data("rj", rj_code, item)
        return item
    
    title_jp = item.get("title_jp", "")
    tags_jp = item.get("tags_jp", [])
    tags_jp = [normalize_tag_id(tag) for tag in tags_jp]

    if not title_jp and not tags_jp:
        logger.warning(f"[ë¶ˆì™„ì „ í•­ëª©] {rj_code}: title_jp/tags_jp ì—†ìŒ")
        # ìˆ˜ì •: ë¶ˆì™„ì „ í•­ëª©ë„ original_filename í•„ë“œ ì¶”ê°€
        original_name = item.get("original") or item.get("title") or ""
        if original_name:
            item["original_filename"] = original_name
        return item

    # title ì •ì œ
    def clean_title(title, rj_code):
        if not title or not rj_code:
            return title
        patterns = [
            rf"[\[\(]?\b{rj_code}\b[\]\)]?[)\s,;ï¼š]*",
            rf"[ _\-]?\bRJ\s*{rj_code[2:]}\b",
            rf"\b{rj_code}\b"
        ]
        for pattern in patterns:
            title = re.sub(pattern, "", title, flags=re.IGNORECASE).strip()
        return title

    cleaned_title = clean_title(title_jp, rj_code)

    # íƒœê·¸ ìºì‹± í™•ì¸ ë° ë²ˆì—­í•  ëª©ë¡ ì¶”ë¦¼
    tags_kr = []
    tags_to_translate = []
    priorities = []

    for tag in tags_jp:
        cached_tag = get_cached_tag(tag)
        if cached_tag:
            tags_kr.append(cached_tag['tag_kr'])
            priorities.append(cached_tag.get('priority', 10))
        else:
            tags_to_translate.append(tag)
            priorities.append(10)

    # ë²ˆì—­
    translated_tags, translated_title = translate_with_gpt_batch(
        tags_to_translate, cleaned_title if needs_translation(cleaned_title) else None, batch_idx=rj_code
    )

    # ìºì‹±
    for i, jp_tag in enumerate(tags_to_translate):
        kr_tag = translated_tags[i]
        cache_tag(jp_tag, kr_tag, priorities[i])
        tags_kr.append(kr_tag)

    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    tag_with_priority = list(zip(tags_kr, priorities))
    tag_with_priority.sort(key=lambda x: x[1], reverse=True)
    tags_kr_sorted = [tag for tag, _ in tag_with_priority]
    primary_tag = tags_kr_sorted[0] if tags_kr_sorted else "ê¸°íƒ€"

    # ìµœì¢… ë°ì´í„° êµ¬ì„±
    final = {
        **item,
        "title_kr": translated_title or cleaned_title or title_jp,
        "tags": tags_kr_sorted,
        "primary_tag": primary_tag,
        "timestamp": time.time()
    }
    
    # ìˆ˜ì •: original_filename í•„ë“œ ì¶”ê°€
    original_name = item.get("original") or item.get("title") or ""
    if original_name:
        final["original_filename"] = original_name

    # ì €ì¥
    cache_data("rj", rj_code, final)
    logger.info(f"[ìë™ ì €ì¥] {rj_code} â†’ {final['title_kr']}")
    return final

@app.route('/check_permanent_failure/<rj_code>', methods=['GET'])
def check_failure(rj_code):
    try:
        doc = db.collection("games").document("rj").collection("items").document(rj_code).get()
        if doc.exists:
            data = doc.to_dict()
            return jsonify({
                "permanent_failure": data.get("status") == "404" or data.get("permanent_error") == True
            })
        return jsonify({"permanent_failure": False})
    except Exception as e:
        logger.error(f"ì‹¤íŒ¨ í™•ì¸ ì˜¤ë¥˜: {e}")
        return jsonify({"permanent_failure": False})

# app.pyì— ì¶”ê°€í•  ì œëª© ë²ˆì—­ í•¨ìˆ˜ë“¤

# ì œëª©ë§Œ ë²ˆì—­í•˜ëŠ” GPT í•¨ìˆ˜
def translate_title_only_with_gpt(title_jp, rj_code=""):
    """ì¼ë³¸ì–´ ì œëª©ë§Œ ê°„ë‹¨íˆ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜"""
    if not openai_client:
        logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        return title_jp
    
    if not title_jp or not needs_translation(title_jp):
        logger.debug(f"ë²ˆì—­ ë¶ˆí•„ìš”: {rj_code}, ì œëª©: {title_jp}")
        return title_jp
    
    try:
        # ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ (ì œëª©ë§Œ ë²ˆì—­)
        prompt = (
            "ë‹¹ì‹ ì€ ì¼ë³¸ì–´ì—ì„œ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.\n"
            "ì•„ë˜ì˜ ì¼ë³¸ì–´ ì œëª©ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.\n"
            "ë²ˆì—­ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ ë²ˆì—­ëœ ì œëª©ë§Œ ë°˜í™˜í•˜ì„¸ìš”.\n\n"
            f"ì œëª©: {title_jp}"
        )

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a translator specializing in Japanese to Korean."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=100
        )
        translated_title = response.choices[0].message.content.strip()
        
        # ë²ˆì—­ ê²°ê³¼ í™•ì¸
        if needs_translation(translated_title):
            logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨: {rj_code}: '{translated_title}'ì€ ì—¬ì „íˆ ì¼ë³¸ì–´ë¡œ ë³´ì„")
            return title_jp  # ì—¬ì „íˆ ì¼ë³¸ì–´ë¡œ ë²ˆì—­ëœ ê²½ìš° ì›ë³¸ ë°˜í™˜
            
        logger.info(f"ë²ˆì—­ ì„±ê³µ: {rj_code}: '{title_jp}' â†’ '{translated_title}'")
        return translated_title
        
    except Exception as e:
        logger.error(f"GPT ì œëª© ë²ˆì—­ ì˜¤ë¥˜: {rj_code}: {e}")
        return title_jp  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜

# ë‹¨ì¼ RJ ì½”ë“œì˜ ì œëª© ë²ˆì—­ í•¨ìˆ˜
def translate_single_rj_title(rj_code):
    """
    ë‹¨ì¼ RJ ì½”ë“œì˜ ì¼ë³¸ì–´ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        rj_code: RJ ì½”ë“œ (ì˜ˆ: "RJ123456")
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
    """
    try:
        # RJ ì½”ë“œ ì •ê·œí™”
        rj_code = rj_code.upper().replace('-', '').replace('_', '').strip()
        if not rj_code.startswith('RJ'):
            rj_code = f"RJ{rj_code}"
            
        logger.info(f"ë‹¨ì¼ ì œëª© ë²ˆì—­ ì‹œì‘: {rj_code}")
        
        # GCSì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        data = get_cached_data('rj', rj_code)
        if not data:
            return {
                'rj_code': rj_code,
                'status': 'error',
                'message': 'ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ'
            }
            
        # ì¼ë³¸ì–´ ì œëª© í™•ì¸
        title_jp = data.get('title_jp')
        if not title_jp:
            return {
                'rj_code': rj_code,
                'status': 'error',
                'message': 'ì¼ë³¸ì–´ ì œëª©(title_jp)ì´ ì—†ìŒ'
            }
            
        # ì´ë¯¸ ì ì ˆí•œ í•œêµ­ì–´ ì œëª©ì´ ìˆëŠ”ì§€ í™•ì¸
        current_title_kr = data.get('title_kr', '')
        if current_title_kr and not needs_translation(current_title_kr):
            return {
                'rj_code': rj_code,
                'status': 'skipped',
                'message': 'ì´ë¯¸ ì ì ˆí•œ í•œêµ­ì–´ ì œëª©ì´ ìˆìŒ',
                'title_kr': current_title_kr
            }
            
        # ì œëª© ë²ˆì—­
        translated_title = translate_title_only_with_gpt(title_jp, rj_code)
        
        # ë²ˆì—­ ê²°ê³¼ ì—…ë°ì´íŠ¸
        if translated_title != title_jp:  # ë²ˆì—­ì´ ì„±ê³µì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê²½ìš°
            data['title_kr'] = translated_title
            data['timestamp'] = time.time()
            
            # GCSì— ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
            cache_data('rj', rj_code, data)
            
            return {
                'rj_code': rj_code,
                'status': 'success',
                'title_jp': title_jp,
                'title_kr': translated_title
            }
        else:
            return {
                'rj_code': rj_code,
                'status': 'unchanged',
                'message': 'ë²ˆì—­ ì‹¤íŒ¨ ë˜ëŠ” ë¶ˆí•„ìš”'
            }
    
    except Exception as e:
        logger.error(f"ì œëª© ë²ˆì—­ ì‹¤íŒ¨: {rj_code}: {e}", exc_info=True)
        return {
            'rj_code': rj_code,
            'status': 'error',
            'message': str(e)
        }

# ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
def batch_translate_rj_titles(rj_codes):
    """
    ì—¬ëŸ¬ RJ ì½”ë“œì˜ ì œëª©ì„ ë°°ì¹˜ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        rj_codes: RJ ì½”ë“œ ëª©ë¡
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ë° ì„¸ë¶€ ê²°ê³¼
    """
    results = []
    successful = 0
    skipped = 0
    errors = 0
    
    logger.info(f"ë°°ì¹˜ ë²ˆì—­ ì‹œì‘: {len(rj_codes)}ê°œ í•­ëª©")
    
    for i, rj_code in enumerate(rj_codes):
        try:
            # ì§„í–‰ ìƒí™© ë¡œê¹… (10ê°œ ë‹¨ìœ„ë¡œ)
            if (i + 1) % 10 == 0 or (i + 1) == len(rj_codes):
                logger.info(f"ì§„í–‰ ìƒí™©: {i+1}/{len(rj_codes)} ì™„ë£Œ")
                
            # ë‹¨ì¼ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ
            result = translate_single_rj_title(rj_code)
            results.append(result)
            
            # ìƒíƒœë³„ ì¹´ìš´í„° ì—…ë°ì´íŠ¸
            if result['status'] == 'success':
                successful += 1
            elif result['status'] == 'skipped':
                skipped += 1
            else:
                errors += 1
                
        except Exception as e:
            logger.error(f"í•­ëª© ì²˜ë¦¬ ì˜¤ë¥˜: {rj_code}: {e}", exc_info=True)
            errors += 1
            results.append({
                'rj_code': rj_code,
                'status': 'error',
                'message': str(e)
            })
    
    summary = {
        'total': len(rj_codes),
        'successful': successful,
        'skipped': skipped,
        'errors': errors
    }
    
    logger.info(f"ë°°ì¹˜ ë²ˆì—­ ì™„ë£Œ: {summary}")
    return {
        'summary': summary,
        'results': results
    }

# ì „ì²´ ë°ì´í„° ì œëª© ë²ˆì—­ í•¨ìˆ˜
def translate_all_rj_titles(batch_size=20, max_items=None):
    """
    ëª¨ë“  RJ ì½”ë“œì˜ ì¼ë³¸ì–´ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­
    
    Args:
        batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  í•­ëª© ìˆ˜
        max_items: ìµœëŒ€ ì²˜ë¦¬í•  í•­ëª© ìˆ˜ (Noneì´ë©´ ì œí•œ ì—†ìŒ)
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ ì •ë³´
    """
    # ì¼ë³¸ì–´ ì œëª©ì´ ìˆê³  í•œêµ­ì–´ ì œëª©ì´ í•„ìš”í•œ í•­ëª© ì°¾ê¸°
    rj_codes_to_translate = []
    
    try:
        # GCS ë˜ëŠ” Firestoreì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        if bucket:
            # GCSì—ì„œ ì°¾ê¸°
            prefix = 'rj/'
            blobs = bucket.list_blobs(prefix=prefix)
            
            for blob in blobs:
                # ê²½ë¡œ í˜•ì‹: rj/prefix/RJXXXXXX.json
                if not blob.name.endswith('.json'):
                    continue
                    
                file_name = blob.name.split('/')[-1]
                rj_code = file_name.split('.')[0].upper()
                
                # ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    data = get_cached_data('rj', rj_code)
                    if data:
                        title_jp = data.get('title_jp', '')
                        title_kr = data.get('title_kr', '')
                        
                        # ì¼ë³¸ì–´ ì œëª©ì´ ìˆê³ , í•œêµ­ì–´ ì œëª©ì´ ì—†ê±°ë‚˜ ì¼ë³¸ì–´ì¸ ê²½ìš°
                        if title_jp and (not title_kr or needs_translation(title_kr)):
                            rj_codes_to_translate.append(rj_code)
                            
                            # ìµœëŒ€ í•­ëª© ìˆ˜ ì œí•œ í™•ì¸
                            if max_items and len(rj_codes_to_translate) >= max_items:
                                logger.info(f"ìµœëŒ€ í•­ëª© ìˆ˜({max_items}) ë„ë‹¬, ê²€ìƒ‰ ì¤‘ë‹¨")
                                break
                except Exception as e:
                    logger.error(f"ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {rj_code}: {e}")
                    continue
        else:
            logger.error("GCS ë²„í‚·ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return {
                'status': 'error',
                'message': 'GCS ë²„í‚·ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ'
            }
    except Exception as e:
        logger.error(f"RJ ì½”ë“œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {
            'status': 'error',
            'message': f"RJ ì½”ë“œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
        }
    
    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
    logger.info(f"ë²ˆì—­ì´ í•„ìš”í•œ í•­ëª©: {len(rj_codes_to_translate)}ê°œ")
    if not rj_codes_to_translate:
        return {
            'status': 'success',
            'message': 'ë²ˆì—­ì´ í•„ìš”í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.',
            'items_found': 0
        }
    
    # ë°°ì¹˜ ì²˜ë¦¬
    total_results = {
        'total_found': len(rj_codes_to_translate),
        'batches': [],
        'successful': 0,
        'skipped': 0,
        'errors': 0
    }
    
    for i in range(0, len(rj_codes_to_translate), batch_size):
        batch = rj_codes_to_translate[i:i+batch_size]
        logger.info(f"ë°°ì¹˜ {i//batch_size + 1}/{(len(rj_codes_to_translate)-1)//batch_size + 1} ì²˜ë¦¬ ì‹œì‘: {len(batch)}ê°œ í•­ëª©")
        
        # ë°°ì¹˜ ì²˜ë¦¬
        batch_result = batch_translate_rj_titles(batch)
        
        # ë°°ì¹˜ ê²°ê³¼ ì €ì¥
        total_results['batches'].append({
            'batch_number': i//batch_size + 1,
            'items': len(batch),
            'summary': batch_result['summary']
        })
        
        # ì „ì²´ ê²°ê³¼ ì—…ë°ì´íŠ¸
        summary = batch_result['summary']
        total_results['successful'] += summary['successful']
        total_results['skipped'] += summary['skipped']
        total_results['errors'] += summary['errors']
        
        logger.info(f"ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: ì„±ê³µ={summary['successful']}, ìŠ¤í‚µ={summary['skipped']}, ì˜¤ë¥˜={summary['errors']}")
    
    logger.info(f"ì „ì²´ ë²ˆì—­ ì™„ë£Œ: ì´={total_results['total_found']}, ì„±ê³µ={total_results['successful']}, ìŠ¤í‚µ={total_results['skipped']}, ì˜¤ë¥˜={total_results['errors']}")
    
    return {
        'status': 'success',
        'message': 'ì „ì²´ ë²ˆì—­ ì™„ë£Œ',
        'results': total_results
    }

# API ì—”ë“œí¬ì¸íŠ¸: ë‹¨ì¼ RJ ì½”ë“œ ì œëª© ë²ˆì—­
@app.route('/translate/title/<rj_code>', methods=['GET'])
def api_translate_title(rj_code):
    try:
        result = translate_single_rj_title(rj_code)
        return jsonify(result)
    except Exception as e:
        logger.error(f"API ë‹¨ì¼ ì œëª© ë²ˆì—­ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

# API ì—”ë“œí¬ì¸íŠ¸: ë°°ì¹˜ ë²ˆì—­
@app.route('/translate/batch', methods=['POST'])
def api_batch_translate():
    try:
        data = request.get_json()
        rj_codes = data.get('rj_codes', [])
        
        if not rj_codes:
            return jsonify({'status': 'error', 'message': 'RJ ì½”ë“œ ëª©ë¡ì´ ë¹„ì–´ ìˆìŒ'}), 400
            
        result = batch_translate_rj_titles(rj_codes)
        return jsonify(result)
    except Exception as e:
        logger.error(f"API ë°°ì¹˜ ë²ˆì—­ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

# API ì—”ë“œí¬ì¸íŠ¸: ì „ì²´ ë²ˆì—­ ì‘ì—… ì‹œì‘
@app.route('/translate/all', methods=['POST'])
def api_translate_all():
    try:
        data = request.get_json()
        batch_size = int(data.get('batch_size', 20))
        max_items = data.get('max_items')
        if max_items is not None:
            max_items = int(max_items)
        
        # ë²ˆì—­ ì‹œì‘
        result = translate_all_rj_titles(batch_size, max_items)
        return jsonify(result)
    except Exception as e:
        logger.error(f"API ì „ì²´ ë²ˆì—­ ì˜¤ë¥˜: {e}", exc_info=True)
        return jsonify({'status': 'error', 'message': str(e)}), 500

if __name__ == '__main__':
    # GCPì—ì„œë§Œ ì‹¤í–‰
    if os.getenv('GAE_ENV', '').startswith('standard') or os.getenv('CLOUD_RUN', '') == 'true':
        app.run(host='0.0.0.0', port=int(os.getenv('PORT', 8080)))
    else:
        logger.warning("ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” GCP í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")